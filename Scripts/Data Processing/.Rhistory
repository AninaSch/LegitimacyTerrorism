plot (y)
y <-  dbinom(46:54, 100, 0.5)
plot (y)
y <-  dbinom(1:10, 100, 0.5)
plot (y)
first_fit <- lm(weight ~ height, data=women)
first_fit <- lm(weight ~ height, data=women)
summary(first_fit)
women$weight
fitted(fit)
residuals(fit)
plot(women$height,women$weight)
abline(fit)
women$weight
fitted(first_fit)
residuals(first_fit)
plot(women$height,women$weight)
abline(first_fit)
fit<-lm(mpg~(hp+wt+hp)^2, data =mtcars)
summary(fit)
fit<-lm(mpg~(hp*wt*hp)^2, data =mtcars)
summary(fit)
library(lme4)
politeness <- read.csv(file.choose())
head(politeness)
View(politeness)
which(is.na(politeness$frequency))
boxplot(frequency ~ attitude*gender, col=c("white","lightgrey"), politeness)
lmer(frequency ~ attitude, data=politeness)
data(Affairs, package="AER")
library(AER)
data(Affairs)
install.packages("AER")
data(Affairs, package="AER")
Affairs$ynaffair[Affairs$affairs == 0] <- 0
Affairs$ynaffair[Affairs$affairs > 0] <- 1
fit<- glm(ynaffair ~ gender + age+yearsmarried + children +religiousness + education + occupation + rating, data=Affairs, family=binomial())
a1 <- rep(1:4, each=2)
a2 <- rep(1:4, each=2)
A <- cbind(a1, a2)
a2 <- rep(1:4, each=2)
A <- cbind(a1, a2)
mean(A[,1])
mean(A[,2])
apply(A, 2, mean)
apply(A, 2, mean)
apply(A, 2, mean, na.rm = TRUE)
A[1,2] <- 1
A
cmeans <- apply(A,2, mean)
A-matrix(cmeans, nrow =4, ncol =2, byrow=2)
A-matrix(cmeans, nrow =4, ncol =2, byrow=TRUE)
A
cmeans <- apply(A,2, mean)
matrix(cmeans, nrow =4, ncol =2, byrow=TRUE)
sweep(A, n, cmeans, FUN= "-")
sweep(A, 2, cmeans, FUN= "-")
source('~/Desktop/NotesMath.R', echo=TRUE)
B <- matrix(1:4, ncol=2, nrow=2)
A %% diag(rep(2,2))
diag(rep(2,2))
A %*% diag(rep(2,2))
theta <- 60
theta2 <- (2*pi*theta)/360
theta
theta2
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
sweep(A, n, cmeans, FUN= "-")
theta
theta2
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
X <- matrix(c(0.7, 1.2, 0.25 0.8), ncol=2)
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
plot(0,0)
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0,1,1)
arrows(0,0,1,1,lwd=3,lenght=0.1)
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0, X[1,], X[2,], lwd=3)
Y <- R %*%X
arrows(0,0, Y[1,], X[2,], lwd=3, col="grey")
arrows(0,0, Y[1,], Y[2,], lwd=3, col="grey")
Y <- R %*%X
Y <- R%*%X
Y <- R %*% X
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
arrows(0,0,1,1,lwd=3,lenght=0.1)
arrows(0,0, X[1,], X[2,], lwd=3)
arrows(0,0,1,1,lwd=3,length=0.1)
arrows(0,0, X[1,], X[2,], lwd=3)
X
Y <- R %*% X
arrows(0,0, Y[1,], Y[2,], lwd=3, col="grey")
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0, X[1,], X[2,], lwd=3)
Y <- R %*% X
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
Y <- R %*% X
X <- matrix(c(0.7, 1.2, 0.25, 0.8), nrow=2, ncol=2)
Y <- R %*% X
u <- c(2,1)
u %*% t8u)
u %*% t(u)
t(u) %*% u
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), nrow=2, ncol=2, byrow=TRUE)
Y <- R %*% X
as.numeric(t(u) %*% u)
Pu <- u %*% t(u)
Pu
Pu <- u %*% t(u)
Pu
Pu <- u %*% t(u) / as.numeric(t(u) %*% u)
Pu
x <- c(2,2)
Pu %*% x
plot(0,0, type="n", xlim=c(0,4), ylim=c(0,3))
abline(0, 0.5, lwd=2, col="blue")
points(2.4,1.2, pch=14)
points(2.4,1.2, pch=16)
points(2,2)
locator(1)
points(x1[1], x1[2], col="red")
points(x1[1], x1[2], col="red")
x1 <- c(0.26,1.73)
points(x1[1], x1[2], col="red")
points(z1[1], z1[2], col="red")
z1 <- c(0.9,0.45)
points(z1[1], z1[2], col="red")
A <-  matrix(c(7,4,3,4,6,4,3,4,7), ncol=3)
A
Ae <- eigen(A)
Ae
Ae$values
Ae[[1]]
D <- diag(Ae$values)
D
V <- Ae$vectors
V %*% D %*% t(V)
A
B <-  matrix(c(-1, -1, 0, 1, 1, 1:10, (1:5)^2, ncol=4))
B
B <-  matrix(c(-1, -1, 0, 1, 1, 1:10, (1:5)^2), ncol=4)
B
Bs <-  svd(B)
Bs
Bs$u %*% diag(Bs$d) %*% t(Bs$v)
x <- seq(20, 50, 1)
y <-  (7000 - 400*x + 10*x^2)/3
plot(x,y,type="l")
y[2]-y[1]
diff(y)
plot (x[-1]], diff(y), type="l")
plot (x[-1], diff(y), type="l")
y <-(7000 - 400*x + 10*x^2)/3
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
# add theoretical derivative
abline(-400/3, 20/3, col=2)
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y)/delta, type="l")
abline(-400/3, 20/3, col=2)
f <-  function(x1,x2) {return(x1^3 - x2^2)}
x1 <- x2 <- seq(-2, 2 , length = 25)
Y <-  outer(x1, x2, f)
persp(x1, x2, Y)
abline(h=0)
abline(v=0)
pmat <- persp(x1, x2, Y, theta = -30)
pmat
p1 <- -0.5
p2 <- -3/4
p3 <- f(p1,p2)
p3
trans3d(p1,p2,p3,pmat)
points(trans3d(p1,p2,p3,pmat), col =2, pch= 16)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
plot(x, y, type ="l")
integrate(dnorm, 0, 1)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
integrate(dnorm, 0, 1)
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1))
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0,01), 1, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgray")
polygon(x0, y0, col = "lightgrey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgrey")
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(-2,2,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(x0, y0, col = "blue")
integrate(dnorm, -2, 2)
pnorm(2) - pnorm(-2)
pnorm(2, 2, 1) - pnorm(-2, 2, 1)
install.packages("RSiena", repos="http://R-Forge.R-project.org")
install.packages("RSiena")
install.packages("RSiena", repos="http://R-Forge.R-project.org", (options(download.file.method = NULL)))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org", options(download.file.method = NULL))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org"), (options(download.file.method = NULL)))
?install.packages
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]])
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]]))
install.packages("RSiena", repos = getOption("http://R-Forge.R-project.org"))
install.packages("RSiena", options(download.file.method = NULL))
install.packages("RSiena")
# loading necessary packages
library(RSiena)
sienaAlgorithmCreate
install.packages("tm")
install.packages("reshape2")
install.packages("tidyverse")
library(tidyverse)
library(rio)
rio::import("/Users/schwarze/Documents/HARVARD/TechTogether")
rio::import(".../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2.xlsx")
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(politeness)
View(fit)
View(first_fit)
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
fairrent <- rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(fairrent)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
library(foreign)
GTD_polity_PENN_PRIO_WGI <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.dta")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
Vdem <- rio::import("../../../Data/Original Data/Vdem/Country_Year_V-Dem_Core_CSV_v9/V-Dem-CY-Core-v9.csv")
Vdem <- rio::import("../../../Data/Original Data/Vdem/Country_Year_V-Dem_Core_CSV_v9/V-Dem-CY-Core-v9.csv")
library(sjlabelled) # to get labels of labelled data
library(Hmisc) # the data labels (variable names)
library(dbplyr)
library(tidyverse)
glimpse(Vdem[,1:10])
# Selected, filtered and renamed data is saved as GTD_clean:
Vdem_tidy <- Vdem %>%
select(
year = year,
country = country_name,
electoral_democracy = v2x_polyarchy,
liberal_democracy = v2x_libdem,
participatory_democracy = v2x_partipdem,
deliberative_democracy = v2x_delibdem,
egalitarian_democracy = v2x_egaldem
) %>%
filter(year > 1999) %>%
mutate(
country = as.factor(country)
) %>% # we sort by country and year (aesthetic):
arrange(country, year)
saveRDS(Vdem_tidy, file = "../../../Data/Processed Data/Vdem_tidy.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
# This script merges the processed data together to create a dataset ready for PANEL ANALYSIS.
# duplicate Fragility & HIEF
# https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/
# duplicated(), unique()
# (duplicated(isTRUE(Fragility)))
# --- 0. Setup
library(tidyverse)
# library(foreign)
source("Other functions/clean_countries.R") # function to clean country names
# --- 1. Load Processed Datasets
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
PRIO <- readRDS("../../Data/Processed Data/Prio_tidy.rds")
WGI <- readRDS("../../Data/Processed Data/WGI_tidy.rds")
WVS <- readRDS("../../Data/Processed Data/WVS_tidy_wave456.rds")
Fragility <- readRDS("../../Data/Processed Data/Fragility_tidy.rds")
HIEF <- readRDS("../../Data/Processed Data/HIEF_tidy.rds")
WDI <- readRDS("../../Data/Processed Data/WDI_tidy.rds")
Vdem <- readRDS("../../Data/Processed Data/Vdem_tidy.rds")
# --- 2. Clean Countries Before Merging
path_to_country_dictionary = "../../Data/Processed Data/To Clean Countries/countries.csv"
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
PENN <- clean_countries(PENN, path_to_country_dictionary)
PRIO <- clean_countries(PRIO, path_to_country_dictionary)
WGI <- clean_countries(WGI, path_to_country_dictionary)
WVS <- clean_countries(WVS, path_to_country_dictionary)
Fragility <- clean_countries(Fragility, path_to_country_dictionary)
WDI <- clean_countries(WDI, path_to_country_dictionary) # check conuntries labelling
HIEF <- clean_countries(HIEF, path_to_country_dictionary)
Vdem <- clean_countries(Vdem, path_to_country_dictionary)
# --- 3. Merging Datasets Polity_Penn_Prio
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
# --- then we merge PENN to GTD_polity:
GTD_polity_PENN <- left_join(GTD_polity, PENN, by = c("consolidated_country", "year"))
# --- then we merge PRIO to GTD_polity_PENN:
GTD_polity_PENN_PRIO <- left_join(GTD_polity_PENN, PRIO, by = c("consolidated_country", "year"))
# because PRIO has only countries in wars, we need to complete the missing values with 0:
GTD_polity_PENN_PRIO <- GTD_polity_PENN_PRIO %>%
replace_na(list(type_of_conflict_1=0, type_of_conflict_2=0,
type_of_conflict_3=0, type_of_conflict_4=0, any_conflict=0))
# --- then we merge WGI to GTD_polity_PENN_PRIO:
GTD_polity_PENN_PRIO_WGI <- left_join(GTD_polity_PENN_PRIO, WGI, by = c("consolidated_country", "year"))
# some duplicate were created, because in some datasets, some year-country combinations happen twice
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>% distinct()
# --- then we merge WVS to GTD_polity_PENN_PRIO_WGI:
GTD_polity_PENN_PRIO_WGI_WVS <- left_join(GTD_polity_PENN_PRIO_WGI, WVS, by = c("consolidated_country"))
# # take years after 2000: (quick dirty fix for the temporary countries):
# GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>%
#   filter(year > 1999)
# GTD_polity_PENN_PRIO_WGI_WVS <- GTD_polity_PENN_PRIO_WGI_WVS %>%
#   filter(year > 1999)
# --- then we merge Fragility to GTD_polity_PENN_PRIO_WGI_WVS:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility <- left_join(GTD_polity_PENN_PRIO_WGI_WVS, Fragility, by = c("consolidated_country", "year"))
# --- then we merge WDI to GTD_polity_PENN_PRIO_WGI_WVS_Fragility:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility, WDI, by = c("consolidated_country", "year"))
# --- then we merge HIEF to GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI, HIEF, by = c("consolidated_country", "year"))
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF %>% distinct()
# --- then we merge Vdem to GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI, Vdem, by = c("consolidated_country", "year"))
# my_dataset <- GTD_polity # until we get our final dataset.
# --- 4. Controls
# we did a left join, matching to GTD countries and year, so it is probable that we miss data from the other dataset.
# TODO: show extend of missing data here, decide how to handle.
# View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
# View(GTD_polity_PENN %>% group_by(consolidated_country) %>% summarise(n_GDP_exp = sum(is.na(GDP_expentiture))))
# NOT DONE, as done while fitting the regression automatically:
# # remove countries with missing or not complete polity data:
# # we do not want countries absent of polity, as polity is our independent variable of interest.
# countries_with_missing_data <- GTD_polity_PENN %>%
#   group_by(consolidated_country) %>%
#   summarise(polity_na_count = sum(is.na(polity)),
#             GDP_exp_na_count = sum(is.na(GDP_expentiture))) %>%
#       filter(polity_na_count > 0 | GDP_exp_na_count > 0) %>%
#       .$consolidated_country
# GTD_polity_PENN <- GTD_polity_PENN %>% filter(!consolidated_country %in% countries_with_missing_data)
#     ### !!!! we removed here important countries, like Germany !!!!!!!!!!!!!!!!!!!!! (because West/East)
# ### !!!! TODO: consolidate their country names when tidying the datasets
# --- 5. Saving
saveRDS(GTD_polity_PENN_PRIO_WGI, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
library(foreign)
GTD_polity_PENN_PRIO_WGI <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.dta")
View(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
library(sjlabelled) # to get labels of labelled data
library(Hmisc) # the data labels (variable names)
library(dbplyr)
library(tidyverse)
HIEF <- rio::import("../../../Data/Original Data/HIEF/HIEF_data.csv")
HIEF <- rio::import("../../../Data/Original Data/HIEF/HIEF_data.csv")
HIEF_tidy <- HIEF %>%
select(
country = Country,
year = Year,
EFindex = EFindex
) %>%
filter(
year >= 1970
# remove missing values that are coded with negative numbers:
) %>%
arrange(country, year) %>%
mutate(country = as.factor(country))
saveRDS(HIEF_tidy, file = "../../../Data/Processed Data/HIEF_tidy.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
# This script merges the processed data together to create a dataset ready for PANEL ANALYSIS.
# duplicate Fragility & HIEF
# https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/
# duplicated(), unique()
# (duplicated(isTRUE(Fragility)))
# --- 0. Setup
library(tidyverse)
# library(foreign)
source("Other functions/clean_countries.R") # function to clean country names
# --- 1. Load Processed Datasets
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
PRIO <- readRDS("../../Data/Processed Data/Prio_tidy.rds")
WGI <- readRDS("../../Data/Processed Data/WGI_tidy.rds")
WVS <- readRDS("../../Data/Processed Data/WVS_tidy_wave456.rds")
Fragility <- readRDS("../../Data/Processed Data/Fragility_tidy.rds")
HIEF <- readRDS("../../Data/Processed Data/HIEF_tidy.rds")
WDI <- readRDS("../../Data/Processed Data/WDI_tidy.rds")
Vdem <- readRDS("../../Data/Processed Data/Vdem_tidy.rds")
path_to_country_dictionary = "../../Data/Processed Data/To Clean Countries/countries.csv"
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
PENN <- clean_countries(PENN, path_to_country_dictionary)
PRIO <- clean_countries(PRIO, path_to_country_dictionary)
WGI <- clean_countries(WGI, path_to_country_dictionary)
WVS <- clean_countries(WVS, path_to_country_dictionary)
Fragility <- clean_countries(Fragility, path_to_country_dictionary)
WDI <- clean_countries(WDI, path_to_country_dictionary) # check conuntries labelling
HIEF <- clean_countries(HIEF, path_to_country_dictionary)
Vdem <- clean_countries(Vdem, path_to_country_dictionary)
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
# --- then we merge PENN to GTD_polity:
GTD_polity_PENN <- left_join(GTD_polity, PENN, by = c("consolidated_country", "year"))
# --- then we merge PRIO to GTD_polity_PENN:
GTD_polity_PENN_PRIO <- left_join(GTD_polity_PENN, PRIO, by = c("consolidated_country", "year"))
# because PRIO has only countries in wars, we need to complete the missing values with 0:
GTD_polity_PENN_PRIO <- GTD_polity_PENN_PRIO %>%
replace_na(list(type_of_conflict_1=0, type_of_conflict_2=0,
type_of_conflict_3=0, type_of_conflict_4=0, any_conflict=0))
# --- then we merge WGI to GTD_polity_PENN_PRIO:
GTD_polity_PENN_PRIO_WGI <- left_join(GTD_polity_PENN_PRIO, WGI, by = c("consolidated_country", "year"))
# some duplicate were created, because in some datasets, some year-country combinations happen twice
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>% distinct()
# --- then we merge WVS to GTD_polity_PENN_PRIO_WGI:
GTD_polity_PENN_PRIO_WGI_WVS <- left_join(GTD_polity_PENN_PRIO_WGI, WVS, by = c("consolidated_country"))
# # take years after 2000: (quick dirty fix for the temporary countries):
# GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>%
#   filter(year > 1999)
# GTD_polity_PENN_PRIO_WGI_WVS <- GTD_polity_PENN_PRIO_WGI_WVS %>%
#   filter(year > 1999)
# --- then we merge Fragility to GTD_polity_PENN_PRIO_WGI_WVS:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility <- left_join(GTD_polity_PENN_PRIO_WGI_WVS, Fragility, by = c("consolidated_country", "year"))
# --- then we merge WDI to GTD_polity_PENN_PRIO_WGI_WVS_Fragility:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility, WDI, by = c("consolidated_country", "year"))
# --- then we merge HIEF to GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI, HIEF, by = c("consolidated_country", "year"))
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF %>% distinct()
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI, Vdem, by = c("consolidated_country", "year"))
View(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem)
glimpse(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem)
# --- then we merge Vdem to GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF, Vdem, by = c("consolidated_country", "year"))
glimpse(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem)
# --- then we merge Vdem to GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem:
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- left_join(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF, Vdem, by = c("consolidated_country", "year"))
# --- 5. Saving
saveRDS(GTD_polity_PENN_PRIO_WGI, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.rds")
saveRDS(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
library(foreign)
GTD_polity_PENN_PRIO_WGI <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_2000.dta")
GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.rds")
write.dta(GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem,  file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_WVS_Fragility_WDI_HIEF_Vdem_2000.dta")
