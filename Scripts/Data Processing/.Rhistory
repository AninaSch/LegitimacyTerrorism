Bs <-  svd(B)
Bs
Bs$u %*% diag(Bs$d) %*% t(Bs$v)
x <- seq(20, 50, 1)
y <-  (7000 - 400*x + 10*x^2)/3
plot(x,y,type="l")
y[2]-y[1]
diff(y)
plot (x[-1]], diff(y), type="l")
plot (x[-1], diff(y), type="l")
y <-(7000 - 400*x + 10*x^2)/3
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
# add theoretical derivative
abline(-400/3, 20/3, col=2)
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y)/delta, type="l")
abline(-400/3, 20/3, col=2)
f <-  function(x1,x2) {return(x1^3 - x2^2)}
x1 <- x2 <- seq(-2, 2 , length = 25)
Y <-  outer(x1, x2, f)
persp(x1, x2, Y)
abline(h=0)
abline(v=0)
pmat <- persp(x1, x2, Y, theta = -30)
pmat
p1 <- -0.5
p2 <- -3/4
p3 <- f(p1,p2)
p3
trans3d(p1,p2,p3,pmat)
points(trans3d(p1,p2,p3,pmat), col =2, pch= 16)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
plot(x, y, type ="l")
integrate(dnorm, 0, 1)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
integrate(dnorm, 0, 1)
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1))
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0,01), 1, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgray")
polygon(x0, y0, col = "lightgrey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgrey")
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(-2,2,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(x0, y0, col = "blue")
integrate(dnorm, -2, 2)
pnorm(2) - pnorm(-2)
pnorm(2, 2, 1) - pnorm(-2, 2, 1)
install.packages("RSiena", repos="http://R-Forge.R-project.org")
install.packages("RSiena")
install.packages("RSiena", repos="http://R-Forge.R-project.org", (options(download.file.method = NULL)))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org", options(download.file.method = NULL))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org"), (options(download.file.method = NULL)))
?install.packages
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]])
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]]))
install.packages("RSiena", repos = getOption("http://R-Forge.R-project.org"))
install.packages("RSiena", options(download.file.method = NULL))
install.packages("RSiena")
# loading necessary packages
library(RSiena)
sienaAlgorithmCreate
install.packages("tm")
install.packages("reshape2")
install.packages("tidyverse")
library(tidyverse)
library(rio)
rio::import("/Users/schwarze/Documents/HARVARD/TechTogether")
rio::import(".../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2.xlsx")
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(politeness)
View(fit)
View(first_fit)
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
fairrent <- rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(fairrent)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
library(tidyverse)
source("Other functions/clean_countries.R") # function to clean country names
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
GTD
glimpse(GTD)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
polity <- rio::import("../../../Data/Original Data/SystemicPeace/p4v2017.xls") # for debugging
library(tidyverse)
polity <- rio::import("../../../Data/Original Data/SystemicPeace/p4v2017.xls") # for debugging
View(polity)
View(polity)
glimpse(polity)
polity_tidy <- polity %>%
select(
year,
country,
polity, polity2,
# democ, autoc,
# xrreg, xrcomp, xropen, xconst, parreg, parcomp, # component variables
exrec, exconst, polcomp, # concept variables
durable, sf # regime durability and state failure
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
# glimpse(polity_tidy)
print("tidying done")
table(polity_tidy$country)
View(polity_tidy)
polity_tidy <- polity %>%
select(
year,
country,
polity, polity2,
# democ, autoc,
# xrreg, xrcomp, xropen, xconst, parreg, parcomp, # component variables
exrec, exconst, polcomp, # concept variables
durable #  regime durability
# sf # state failure
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
table(polity_tidy$polity)
table(polity_tidy$polity2)
table(polity_tidy$polity, useNA='any')
table(polity_tidy$polity, useNA='ifany')
table(polity_tidy$polity2, useNA='ifany')
#       0. setup
library(rio) # to import and export data
library(tidyverse) # data wrangling etc.
# --- 1. tidy GTD:
source("Functions to Tidy Data/tidy_GTD.R")
path_loadoriginal = "../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx" # path to original data
path_savetidy = "../../Data/Processed Data/GTD_tidy.rds"
tidy_GTD(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
#       0. setup
library(rio) # to import and export data
library(tidyverse) # data wrangling etc.
# --- 1. tidy GTD:
source("Functions to Tidy Data/tidy_GTD.R")
path_loadoriginal = "../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx" # path to original data
path_savetidy = "../../Data/Processed Data/GTD_tidy.rds"
tidy_GTD(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
# --- 2. tidy PolityIV:
source("Functions to Tidy Data/tidy_Polity4.R")
path_loadoriginal = "../../Data/Original Data/SystemicPeace/p4v2017.xls"
path_savetidy = "../../Data/Processed Data/polity_tidy.rds"
tidy_polity4(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
# Tidy All the Necessary Data.
# This "main" script reads all the separate "Scripts to Tidy Data/Data_tidy.R" scripts used to tidy the data.
# Working Directory has to be set to this file's location.
# This file take a few minutes to run
#       0. setup
library(rio) # to import and export data
library(tidyverse) # data wrangling etc.
# --- 1. tidy GTD:
source("Functions to Tidy Data/tidy_GTD.R")
path_loadoriginal = "../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx" # path to original data
path_savetidy = "../../Data/Processed Data/GTD_tidy.rds"
tidy_GTD(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
# no need to worry about the warnings of rio::import
# --- 2. tidy PolityIV:
source("Functions to Tidy Data/tidy_Polity4.R")
path_loadoriginal = "../../Data/Original Data/SystemicPeace/p4v2017.xls"
path_savetidy = "../../Data/Processed Data/polity_tidy.rds"
tidy_Polity4(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
glimpse(WVS)
View(WVS)
library(sjlabelled) # to get labels of labelled data
label(WVS)
library(Hmisc) # the data labels (variable names)
label(WVS)
WWS[1:10]
WVS[1:10]
WVS_tidy <- WVS %>%
select(
country = S003,
year = S020,
# A165, # Most people can be trusted
interpersonal_trust = G007_64, # Trust: People in general
A004, # Important in life: Politics
A004_CO, # Politics important
political_interest = E023, # Interest in politics
E150, # How often follows politics in the news
A062 # How often discusses political matters with friends
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
View(WVS_tidy)
WVS_tidy <- WVS %>%
select(
country = S003,
year = S020,
# A165, # Most people can be trusted
interpersonal_trust = G007_64, # Trust: People in general
# A004, # Important in life: Politics
# A0C04_CO, # Politics important
political_interest = E023, # Interest in politics
# E150, # How often follows politics in the news
# A062 # How often discusses political matters with friends
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
View(WVS_tidy)
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
# glimpse(WVS)
print("importing done")
wws_labels <- label(WVS)
WVS$S003
# as the data is encoded, we need to decode the variables that interest us.
# e.g. country is a number and should be a name etc.
# 1. COUNTRY - S003
# https://cran.r-project.org/web/packages/sjlabelled/vignettes/labelleddata.html
WVS <- WVS %>% mutate(S003_country = sjlabelled::as_label(WVS$S003))
glimpse(WVS)
WVS_tidy <- WVS %>%
select(
country = S003_country,
year = S020,
# A165, # Most people can be trusted
interpersonal_trust = G007_64, # Trust: People in general
# A004, # Important in life: Politics
# A0C04_CO, # Politics important
political_interest = E023, # Interest in politics
# E150, # How often follows politics in the news
# A062 # How often discusses political matters with friends
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
View(WVS_tidy)
table(WVS_tidy$country)
table(WVS_tidy$year)
table(WVS_tidy$interpersonal_trust)
table(WVS_tidy$political_interest)
table(WVS_tidy$political_interest, useNA = "ifany")
wws_political_interest <- WVS_tidy %>%
select(year, country, political_interest) %>%
# no missing data
group_by(year, country) %>%
# group_by(country) %>%
summarise(avg_political_interest = mean(political_interest)) %>%
arrange(country, year)
View(wws_political_interest)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
#       0. setup
library(rio) # to import and export data
library(tidyverse) # data wrangling etc.
# --- 2. tidy WVS:
source("Functions to Tidy Data/tidy_WVS.R")
path_loadoriginal = "../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds"
path_savetidy = "../../Data/Processed Data/WVS_tidy.rds"
tidy_WVS(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
penn <- rio::import("../../../Data/Original Data/PENNWorldTable/pwt91new.xls") # for debugging
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
penn <- rio::import("../../../Data/Original Data/PENNWorldTable/pwt91new.xls") # for debugging
penn <- rio::import("../../../Data/Original Data/PENNWorldTable/pwt91new.xlsx") # for debugging
glimpse(penn)
penn <- rio::import("../../../Data/Original Data/PENNWorldTable/pwt91new.xlsx") # for debugging
glimpse(penn)
PENN_tidy <- penn %>%
select(
year,
country,
GDP_expentiture = rgdpe,
GDP_output = rgdpo,
pop
) %>%
filter(
year >= 1970
) %>%
mutate(country = as.factor(country)) %>%
arrange(country, year)
View(PENN_tidy)
table(PENN_tidy$country)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
# --- 4. tidy Penn:
source("Functions to Tidy Data/tidy_PENN.R")
path_loadoriginal = "../../Data/Original Data/PENNWorldTable/pwt91new.xlsx"
path_savetidy = "../../Data/Processed Data/WVS_PENN.rds"
tidy_PENN(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
# --- 4. tidy Penn:
source("Functions to Tidy Data/tidy_PENN.R")
path_loadoriginal = "../../Data/Original Data/PENNWorldTable/pwt91new.xlsx"
path_savetidy = "../../Data/Processed Data/WVS_PENN.rds"
tidy_PENN(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
# --- 4. tidy Penn:
source("Functions to Tidy Data/tidy_PENN.R")
path_loadoriginal = "../../Data/Original Data/PENNWorldTable/pwt91new.xlsx"
path_savetidy = "../../Data/Processed Data/PENN_tidy.rds"
tidy_PENN(path_loadoriginal, path_savetidy) # import original, clean, tidy, save in processed data
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing")
library(tidyverse)
source("Other functions/clean_countries.R") # function to clean country names
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
PENN_tidy$country %>% unique()
# This script merges the processed data together to create a dataset ready for the modelling.
# --- 0. Setup
library(tidyverse)
source("Other functions/clean_countries.R") # function to clean country names
# --- 1. Load Processed Datasets
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
# --- 2. Clean Countries Before Merging
path_to_country_dictionary = "../../Data/Processed Data/To Clean Countries/countries.csv"
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
# --- 3. Merging Datasets
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
# and we do not want countries absent of polity, as polity is our independent variable of interest.
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
# --- then we merge XXX to GTD_polity:
# etc.
# my_dataset <- GTD_polity # until we get our final dataset.
# --- 4. Controls
# we did a left join, matching to GTD countries and year, so it is probable that we miss data from the other dataset.
# TODO: show extend of missing data here, decide how to handle.
View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
# remove countries with missing or not complete polity data:
countries_with_missing_data <- GTD_polity %>%
group_by(consolidated_country) %>%
summarise(polity_na_count = sum(is.na(polity))) %>%
filter(polity_na_count > 0) %>%
.$consolidated_country
GTD_polity <- GTD_polity %<% filter()
### !!!! we removed here important countries, like Germany !!!!!!!!!!!!!!!!!!!!! (because West/East)
### !!!! TODO: consolidate their country names when tidying the datasets
# --- 5. Saving
saveRDS(GTD_polity, file = "../../Data/Data for Modelling/first_dataset_to_try.rds")
library(tidyverse)
source("Other functions/clean_countries.R") # function to clean country names
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
PENN <- clean_countries(PENN, path_to_country_dictionary)
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
View(GTD_polity)
View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
countries_with_missing_data <- GTD_polity %>%
group_by(consolidated_country) %>%
summarise(polity_na_count = sum(is.na(polity))) %>%
filter(polity_na_count > 0) %>%
.$consolidated_country
countries_with_missing_data
View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
GTD_polity <- GTD_polity %<% filter(!consolidated_country %in% countries_with_missing_data)
GTD_polity$consolidated_country %>% unique()
GTD_polity <- GTD_polity %>% filter(!consolidated_country %in% countries_with_missing_data)
GTD_polity$consolidated_country %>% unique()
GTD_polity$consolidated_country %>% unique() %>% count()
GTD_polity$consolidated_country %>% unique() %>% dim()
GTD_polity$consolidated_country %>% unique() %>% length()
View(GTD_polity)
glimpse(PENN)
# --- then we merge PENN to GTD_polity:
GTD_polity_PENN <- left_join(GTD_polity, PENN, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country)
View(GTD_polity_PENN %>% group_by(consolidated_country) %>% summarise(n_GDP_exp = sum(is.na(GDP_expentiture))))
View(GTD_polity_PENN %>% group_by(consolidated_country) %>% summarise(n_GDP_exp = sum(is.na(GDP_expentiture))))
View(GTD_polity_PENN)
# remove countries with missing or not complete polity data:
# we do not want countries absent of polity, as polity is our independent variable of interest.
countries_with_missing_data <- GTD_polity_PENN %>%
# remove countries with missing or not complete polity data:
# we do not want countries absent of polity, as polity is our independent variable of interest.
countries_with_missing_data <- GTD_polity_PENN %>%
group_by(consolidated_country) %>%
summarise(polity_na_count = sum(is.na(polity)),
GDP_exp_na_count = sum(is.na(GDP_expentiture))) %>%
filter(polity_na_count > 0 | GDP_exp_na_count > 0) %>%
.$consolidated_country
GTD_polity_PENN <- GTD_polity_PENN %>% filter(!consolidated_country %in% countries_with_missing_data)
View(GTD_polity_PENN)
saveRDS(GTD_polity_PENN, file = "../../Data/Data for Modelling/GTD_polity_PENN.rds")
library(tidyverse)
library(pglm) # model panel data
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN.rds")
library(tidyverse)
library(pglm) # model panel data
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN.rds")
View(my_data)
table(my_data$exrec, useNA = "ifany")
table(my_data$exconst, useNA = "ifany")
table(my_data$polcomp, useNA = "ifany")
table(my_data$durable, useNA = "ifany")
table(my_data$GDP_expentiture, useNA = "ifany")
glimpse(my_data)
# for now, just remove all the polity score larger than 10 (absolute value)
# (this should be done in tidy_Polity4.R)
my_data <- my_data %>% filter(abs(polity) < 11) # ! we go from 5282 row to 6999
table(my_data$exrec, useNA = "ifany")
table(my_data$exconst, useNA = "ifany")
table(my_data$polcomp, useNA = "ifany")
?pglm
library(pglm) # model panel data
install.packages("pglm")
library(pglm) # model panel data
?pglm
glimpse(my_data)
# set my data as panel data
pdata <- pdata.frame(my_data, index = c("consolidated_country", "year")) # not necessary, could also probably be done when calling pglm
# # summary statistics:
summary(Y)
# random effect estimator (CORRECT ONE?)
formula = 'had_events ~ exrec + exconst + polcomp + durable + GDP_expentiture + pop'
log_reg <- pglm(formula = formula, data = pdata, estimator = "random", family = 'binomial')
summary(log_reg)
# random effect estimator (CORRECT ONE?)
my_formula = 'had_events ~ exrec + exconst + polcomp + durable + GDP_expentiture + pop'
log_reg <- pglm(formula = my_formula, data = pdata, estimator = "random", family = 'binomial')
log_reg <- pglm(had_events ~ exrec + exconst + polcomp + durable + GDP_expentiture + pop,
data = pdata, estimator = "random", family = 'binomial')
summary(log_reg)
# random effect estimator (CORRECT ONE?)
log_reg <- pglm(had_events ~ exrec + exconst + polcomp + durable + GDP_expentiture + pop,
data = pdata, estimator = "pooling", family = 'binomial')
summary(log_reg)
# ----------------  negative binomial :
# for negbin: family = negbin. and Y=n_events
neg_bin <- pglm(formula = n_events ~ exrec + GDP_expentiture + pop, data = pdata, estimator = "random", family = 'negbin')
summary(neg_bin)
# ----------------  negative binomial :
# for negbin: family = negbin. and Y=n_events
neg_bin <- pglm(formula = n_events ~ exrec, data = pdata, estimator = "random", family = 'negbin')
glimpse(my_data)
# ----------------  negative binomial :
# for negbin: family = negbin. and Y=n_events
neg_bin <- pglm(formula = n_events ~ polity, data = pdata, estimator = "random", family = 'negbin')
summary(neg_bin)
# ----------------  negative binomial :
# for negbin: family = negbin. and Y=n_events
neg_bin <- pglm(formula = n_events ~ polity, data = pdata, estimator = "random", family = 'negbin')
summary(neg_bin)
glimpse(my_data)
View(my_data)
library(tidyverse)
library(pglm) # model panel data
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN.rds")
# for now, just remove all the polity score larger than 10 (absolute value)
# (this should be done in tidy_Polity4.R)
my_data <- my_data %>% filter(abs(polity) < 11) # ! we go from 5282 row to 5088
pglm
?pglm
install.packages("lme4")
