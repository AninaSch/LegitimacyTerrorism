WGI <- readRDS("../../Data/Processed Data/WGI_tidy.rds")
path_to_country_dictionary = "../../Data/Processed Data/To Clean Countries/countries.csv"
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
PENN <- clean_countries(PENN, path_to_country_dictionary)
PRIO <- clean_countries(PRIO, path_to_country_dictionary)
WGI <- clean_countries(WGI, path_to_country_dictionary)
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
# --- then we merge PENN to GTD_polity:
GTD_polity_PENN <- left_join(GTD_polity, PENN, by = c("consolidated_country", "year"))
# --- then we merge PRIO to GTD_polity_PENN:
GTD_polity_PENN_PRIO <- left_join(GTD_polity_PENN, PRIO, by = c("consolidated_country", "year"))
View(GTD_polity_PENN_PRIO)
glimpse(GTD_polity_PENN_PRIO_WGI)
glimpse(GTD_polity_PENN_PRIO)
# because PRIO has only countries in wars, we need to complete the missing values with 0:
GTD_polity_PENN_PRIO <- GTD_polity_PENN_PRIO %>%
replace_na(list(type_of_conflict_1=0, type_of_conflict_2=0,
type_of_conflict_3=0, type_of_conflict_4=0, any_conflict=0))
View(GTD_polity_PENN_PRIO)
# --- then we merge WGI to GTD_polity_PENN_PRIO:
GTD_polity_PENN_PRIO_WGI <- left_join(GTD_polity_PENN_PRIO, WGI, by = c("consolidated_country", "year"))
# some duplicate were created, because in some datasets, some year-country combinations happen twice
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>% distinct()
# take years after 2000: (quick dirty fix for the temporary countries):
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>%
filter(year > 1999)
View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
# This script merges the processed data together to create a dataset ready for PANEL ANALYSIS.
# --- 0. Setup
library(tidyverse)
source("Other functions/clean_countries.R") # function to clean country names
# --- 1. Load Processed Datasets
GTD <- readRDS("../../Data/Processed Data/GTD_tidy.rds")
polity <- readRDS("../../Data/Processed Data/polity_tidy.rds")
PENN <- readRDS("../../Data/Processed Data/PENN_tidy.rds")
PRIO <- readRDS("../../Data/Processed Data/Prio_tidy.rds")
WGI <- readRDS("../../Data/Processed Data/WGI_tidy.rds")
# WVS <- readRDS("../../Data/Processed Data/WVS_tidy.rds")
# --- 2. Clean Countries Before Merging
path_to_country_dictionary = "../../Data/Processed Data/To Clean Countries/countries.csv"
GTD <- clean_countries(GTD, path_to_country_dictionary)
polity <- clean_countries(polity, path_to_country_dictionary)
PENN <- clean_countries(PENN, path_to_country_dictionary)
PRIO <- clean_countries(PRIO, path_to_country_dictionary)
WGI <- clean_countries(WGI, path_to_country_dictionary)
# --- 3. Merging Datasets Polity_Penn_Prio
# --- we start by merging polity to GTD:
# we do an left join, as we do not want countries that are not in the GTD (true? we could also set n_events to 0 for those?)
GTD_polity <- left_join(GTD, polity, by = c("consolidated_country", "year")) %>%
arrange(consolidated_country) # set order by country, for aesthetics and readability
# --- then we merge PENN to GTD_polity:
GTD_polity_PENN <- left_join(GTD_polity, PENN, by = c("consolidated_country", "year"))
# --- then we merge PRIO to GTD_polity_PENN:
GTD_polity_PENN_PRIO <- left_join(GTD_polity_PENN, PRIO, by = c("consolidated_country", "year"))
# because PRIO has only countries in wars, we need to complete the missing values with 0:
GTD_polity_PENN_PRIO <- GTD_polity_PENN_PRIO %>%
replace_na(list(type_of_conflict_1=0, type_of_conflict_2=0,
type_of_conflict_3=0, type_of_conflict_4=0, any_conflict=0))
# --- then we merge WGI to GTD_polity_PENN_PRIO:
GTD_polity_PENN_PRIO_WGI <- left_join(GTD_polity_PENN_PRIO, WGI, by = c("consolidated_country", "year"))
# some duplicate were created, because in some datasets, some year-country combinations happen twice
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>% distinct()
# still 5 "duplicates" left:
# check later
# take years after 2000: (quick dirty fix for the temporary countries):
GTD_polity_PENN_PRIO_WGI <- GTD_polity_PENN_PRIO_WGI %>%
filter(year > 1999)
# my_dataset <- GTD_polity # until we get our final dataset.
# --- 4. Controls
# we did a left join, matching to GTD countries and year, so it is probable that we miss data from the other dataset.
# TODO: show extend of missing data here, decide how to handle.
# View(GTD_polity %>% group_by(consolidated_country) %>% summarise(polity_na_count = sum(is.na(polity))))
# View(GTD_polity_PENN %>% group_by(consolidated_country) %>% summarise(n_GDP_exp = sum(is.na(GDP_expentiture))))
# NOT DONE, as done while fitting the regression automatically:
# # remove countries with missing or not complete polity data:
# # we do not want countries absent of polity, as polity is our independent variable of interest.
# countries_with_missing_data <- GTD_polity_PENN %>%
#   group_by(consolidated_country) %>%
#   summarise(polity_na_count = sum(is.na(polity)),
#             GDP_exp_na_count = sum(is.na(GDP_expentiture))) %>%
#       filter(polity_na_count > 0 | GDP_exp_na_count > 0) %>%
#       .$consolidated_country
# GTD_polity_PENN <- GTD_polity_PENN %>% filter(!consolidated_country %in% countries_with_missing_data)
#     ### !!!! we removed here important countries, like Germany !!!!!!!!!!!!!!!!!!!!! (because West/East)
# ### !!!! TODO: consolidate their country names when tidying the datasets
# --- 5. Saving
saveRDS(GTD_polity_PENN_PRIO_WGI, file = "../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Modelling")
library(tidyverse)
library(pglm) # model panel data
library(pscl)
library(lme4) # models longitudinal data within a Generalized Linear Mixed Model (GLMM) framework,
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
View(my_data)
descriptive(my_data$exconst)
table(my_data$exconst)
table(my_data$polcomp)
table(my_data$exrec)
# legitimacy polity measures
la <- pglm(n_events ~ exrec + exconst + polcomp,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
# lagged legitimacy
la <- pglm(n_events ~ lag(exrec) + exconst + polcomp,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
# lagged legitimacy
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ polity2 + durable + log(GDP_expentiture) + log(pop),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ polity2 + durable + log(GDP_expentiture) + log(pop),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ exrec + exconst + polcomp + durable + log(GDP_expentiture) + log(pop),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ exrec + exconst + polcomp + durable + log(GDP_expentiture) + log(pop) + any_conflict,  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) ,  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_output)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_output)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
glimpse(my_data)
# legitimacy
la <- pglm(n_events ~ accountability + corruption + effectiveness + quality + rule_of_law,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
# lagged legitimacy
la <- pglm(n_events ~ lag(accountability) + lag(corruption) + lag(effectiveness) + lag(quality) + lag(rule_of_law),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(accountability) + lag(corruption) + lag(effectiveness) + lag(quality) + lag(rule_of_law) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict) +lag(stability),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
# standardize data
my_data.scl <- scale(my_data)
colMeans(my_data.scl)
# standardize data
my_data.scl <- scale(my_data)
my_data %<%
standardize(GDP_expentiture, centerFun = mean, scaleFun = sd)
my_data %<%
standardize(my_data$GDP_expentiture, centerFun = mean, scaleFun = sd)
standardize(my_data$GDP_expentiture, centerFun = mean, scaleFun = sd)
install.packages("robustHD")
# Note that glmer implements random, rather than fixed effects.
# If you're attempting inference and want to control for all cross-sectional heterogeneity, glmer won't get you there. You'd need some implementation of the conditional logit model
library(robustHD)
standardize(my_data$GDP_expentiture, centerFun = mean, scaleFun = sd)
my_data.scl <- my_data %>% mutate_each_(funs(scale(.) %>% as.vector),
vars=c("GDP_expentiture","pop"))
View(my_data.scl)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(GDP_output) + lag(pop) + lag(any_conflict),  my_data.scl,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
la <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(GDP_output) + lag(pop) + lag(any_conflict),  my_data.scl,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(la)
pnb <- pglm(n_events ~ lag(exrec, n=2L) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
pnb <- pglm(n_events ~ lag(exrec, n=2L) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
pnb <- pglm(n_events ~ lag(accountability, n=2L) + lag(corruption, n=2L) + lag(effectiveness, n=2L) + lag(quality, n=2L) + lag(rule_of_law, n=2L) + lag(log(GDP_expentiture), n=2L) + lag(log(pop), n=2L) + lag(any_conflict, n=2L) +lag(stability, n=2L),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
?pglm
# random effects
pnb <- pglm(n_events ~ lag(accountability, n=2L) + lag(corruption, n=2L) + lag(effectiveness, n=2L) + lag(quality, n=2L) + lag(rule_of_law, n=2L) + lag(log(GDP_expentiture), n=2L) + lag(log(pop), n=2L) + lag(any_conflict, n=2L) +lag(stability, n=2L),  my_data,
family = negbin, model = "random", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
# random effects
pnb <- pglm(n_events ~ lag(accountability, n=2L) + lag(corruption, n=2L) + lag(effectiveness, n=2L) + lag(quality, n=2L) + lag(rule_of_law, n=2L) + lag(log(GDP_expentiture), n=2L) + lag(log(pop), n=2L) + lag(any_conflict, n=2L) +lag(stability, n=2L),  my_data,
family = negbin, model = "random", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
WVS <- readRDS("../../Data/Processed Data/WVS_tidy.rds")
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
# wws_labels <- label(WVS)
# wws_labels[[1]] to access only the label.
# as the data is encoded, we need to decode the variables that interest us.
# e.g. country is a number and should be a name etc.
# 1. COUNTRY - S003
# https://cran.r-project.org/web/packages/sjlabelled/vignettes/labelleddata.html
WVS <- WVS %>% mutate(S003_country = sjlabelled::as_label(WVS$S003))
WVS_tidy <- WVS %>%
select(
country = S003_country,
year = S020,
wave = S002,
trust_others	=	A165,	#	Most people can be trusted
# general_trust_citizen	=	G007_01,	#	Trust: Other people in country
# general_trust_people	=	G007_64,	#	Trust: People in general
importance_politics	=	A004,	#	Important in life: Politics
interest_politics1	=	E023,	#	Interest in politics
# interest_politics2	=	E024,	#	Interest in politics (ii)
# follow_politics	=	E150	#	How often follows politics in the news
) %>%
filter(
year >= 1970
) %>%
arrange(country, year) %>%
mutate(country = as.factor(country))
WVS_tidy_wave6 <- WVS_tidy %>%
filter(wave == 6) %>%
group_by(country) %>%
summarise(
mean_trust_others = mean(trust_others, na.rm=TRUE),
mean_importance_politics = mean(importance_politics, na.rm=TRUE),
mean_interest_politics1 = mean(interest_politics1, na.rm=TRUE),
std_trust_others = sd(trust_others, na.rm=TRUE),
std_importance_politics = sd(importance_politics, na.rm=TRUE),
std_interest_politics1 = sd(interest_politics1, na.rm=TRUE)
) %>%
arrange()
View(WVS_tidy_wave6)
View(WVS_tidy)
View(WVS)
library(tidyverse)
library(pglm) # model panel data
library(pscl)
library(lme4) # models longitudinal data within a Generalized Linear Mixed Model (GLMM) framework,
# Note that glmer implements random, rather than fixed effects.
# If you're attempting inference and want to control for all cross-sectional heterogeneity, glmer won't get you there. You'd need some implementation of the conditional logit model
library(robustHD) # data standardization
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
# scale only specific variable names
my_data.scl <- my_data %>% mutate_each_(funs(scale(.) %>% as.vector),
vars=c("GDP_expentiture","pop"))
# legitimacy
pnb <- pglm(n_events ~ exrec + exconst + polcomp,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
# scale only specific variable names
my_data.scl <- my_data %>% mutate_each_(funs(scale(.) %>% as.vector),
vars=c("GDP_expentiture","pop"))
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Modelling")
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
# scale only specific variable names
my_data.scl <- my_data %>% mutate_each_(funs(scale(.) %>% as.vector),
vars=c("GDP_expentiture","pop"))
table(my_data$exrec)
# legitimacy
pnb <- pglm(n_events ~ exrec + exconst + polcomp,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
# lagged legitimacy
pnb <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
pnb <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
# Does not converge with GDP output
nb <- pglm(n_events ~ lag(exrec) + lag(exconst) + lag(polcomp) + lag(durable) + lag(log(GDP_output)) + lag(log(pop)) + lag(any_conflict),  my_data,
family = negbin(link="log"), model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
?pglm
with(my_data,plot(log(GDP_output),log(GDP_expentiture)) )
# legitimacy
pnb <- pglm(n_events ~ accountability + corruption + effectiveness + quality + rule_of_law,  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
warnings()
summary(pnb)
coef(pnb)
exp(coef(pnb))
# lagged legitimacy
pnb <- pglm(n_events ~ lag(accountability) + lag(corruption) + lag(effectiveness) + lag(quality) + lag(rule_of_law),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
pnb <- pglm(n_events ~ lag(accountability) + lag(corruption) + lag(effectiveness) + lag(quality) + lag(rule_of_law) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict) +lag(stability),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
exp(coef(pnb))
exp(cbind(coef(pnb), confint(pnb)))
pnb <- pglm(n_events ~ lag(accountability) + lag(corruption) + lag(effectiveness) + lag(quality) + lag(rule_of_law) + lag(log(GDP_expentiture)) + lag(log(pop)) + lag(any_conflict) +lag(stability),  my_data,
family = negbin, model = "within", print.level = 3, method = "nr",
index = c('consolidated_country', 'year'))
summary(pnb)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
# glimpse(WVS)
print("importing done")
# as the data is encoded, we need to decode the variables that interest us.
# e.g. country is a number and should be a name etc.
# 1. COUNTRY - S003
# https://cran.r-project.org/web/packages/sjlabelled/vignettes/labelleddata.html
WVS <- WVS %>% mutate(S003_country = sjlabelled::as_label(WVS$S003))
library(sjlabelled) # to get labels of labelled data
library(Hmisc) # the data labels (variable names)
library(dbplyr)
library(tidyverse)
# read WVS Data
print("importing WVS data... (1min) ")
WVS <- rio::import(path_loadoriginal)
WVS <- rio::import("../../../Data/Original Data/WorldValueSurvey/F00008390-WVS_Longitudinal_1981_2016_r_v20180912.rds") # for debugging
# glimpse(WVS)
print("importing done")
# as the data is encoded, we need to decode the variables that interest us.
# e.g. country is a number and should be a name etc.
# 1. COUNTRY - S003
# https://cran.r-project.org/web/packages/sjlabelled/vignettes/labelleddata.html
WVS <- WVS %>% mutate(S003_country = sjlabelled::as_label(WVS$S003))
WVS_tidy <- WVS %>%
select(
country = S003_country,
year = S020,
wave = S002,
trust_others	=	A165,	#	Most people can be trusted
# general_trust_citizen	=	G007_01,	#	Trust: Other people in country
# general_trust_people	=	G007_64,	#	Trust: People in general
importance_politics	=	A004,	#	Important in life: Politics
interest_politics1	=	E023,	#	Interest in politics
# interest_politics2	=	E024,	#	Interest in politics (ii)
# follow_politics	=	E150	#	How often follows politics in the news
) %>%
filter(
year >= 1970
) %>%
arrange(country, year) %>%
mutate(country = as.factor(country))
View(WVS_tidy)
group_by()
?group(by)
WVS_tidy_wave1 <- WVS_tidy %>%
filter(wave == 6) %>%
group_by(country, year) %>%
summarise(
mean_trust_others = mean(trust_others, na.rm=TRUE),
mean_importance_politics = mean(importance_politics, na.rm=TRUE),
mean_interest_politics1 = mean(interest_politics1, na.rm=TRUE),
std_trust_others = sd(trust_others, na.rm=TRUE),
std_importance_politics = sd(importance_politics, na.rm=TRUE),
std_interest_politics1 = sd(interest_politics1, na.rm=TRUE)
) %>%
arrange()
WVS_tidy_wave1
WVS_tidy_wave1 <- WVS_tidy %>%
filter(wave == 1) %>%
group_by(country, year) %>%
summarise(
mean_trust_others = mean(trust_others, na.rm=TRUE),
mean_importance_politics = mean(importance_politics, na.rm=TRUE),
mean_interest_politics1 = mean(interest_politics1, na.rm=TRUE),
std_trust_others = sd(trust_others, na.rm=TRUE),
std_importance_politics = sd(importance_politics, na.rm=TRUE),
std_interest_politics1 = sd(interest_politics1, na.rm=TRUE)
) %>%
arrange()
View(WVS_tidy_wave1)
?filter()
??filter()
filter(WS_tidy, wave==2)
View(WVS_tidy)
WVS_tidy$year
table(WVS_tidy$year)
?mean
VS_tidy_aggregate <- WVS_tidy %>%
group_by(country, year) %>%
summarise(
mean_trust_others = mean(trust_others, na.rm=TRUE),
mean_importance_politics = mean(importance_politics, na.rm=TRUE),
mean_interest_politics1 = mean(interest_politics1, na.rm=TRUE)
) %>%
arrange()
View(VS_tidy_aggregate)
WVS_tidy %>% filter(country == "Albania", year = 1998) %>% View()
WVS_tidy %>% filter(country == "Albania", year == 1998) %>% View()
WVS_tidy %>% filter(country == "Albania", year == 1998) %>% .$trust_others
WVS_tidy %>% filter(country == "Albania", year == 1998) %>% .$trust_others %>% mean()
WVS_tidy %>% filter(country == "Albania", year == 1998) %>% .$trust_others %>% median()
table(WVS_tidy$interest_politics1)
table(WVS_tidy$importance_politics)
table(WVS_tidy$trust_others)
WVS_tidy_aggregate <- WVS_tidy %>%
group_by(country, year) %>%
summarise(
mean_trust_others = mean(trust_others, na.rm=TRUE),
mean_importance_politics = mean(importance_politics, na.rm=TRUE),
mean_interest_politics1 = mean(interest_politics1, na.rm=TRUE)
) %>%
arrange(country, year)
table(WVS_tidy$country, WVS_tidy$year)
table(WVS_tidy$country, WVS_tidy$year) %>% View()
table(WVS_tidy$country, WVS_tidy$year) %>% tail()
table(WVS_tidy$country, WVS_tidy$year) %>% tail(100)
View(WVS_tidy_aggregate)
ggplot(data=WVS_tidy_aggregate, aes(x=year, y=mean_trust_others, group=country)) +
geom_line()+
geom_point()
ggplot(data=WVS_tidy_aggregate, aes(x=year, y=mean_trust_others, group=country)) +
geom_line() +
geom_point()  + theme_bw()
ggplot(data=head(WVS_tidy_aggregate), aes(x=year, y=mean_trust_others, group=country)) +
geom_line() +
geom_point()  + theme_bw()
WVS_agg_subset = WVS_tidy_aggregate %>% filter(
country %in% c("Russia", "Poland", "Peru", "Nigeria", "Norway", "Mexico")
)
ggplot(data=WVS_tidy_aggregate, aes(x=year, y=mean_trust_others, group=country)) +
geom_line() +
geom_point()  + theme_bw()
ggplot(data=WVS_agg_subset, aes(x=year, y=mean_trust_others, group=country)) +
geom_line() +
geom_point()  + theme_bw()
vis_dat(WVS_tidy)
library(visdat) # visual inspection of data
vis_dat(WVS_tidy)
vis_dat(WVS_tidy_aggregate)
vis_miss(WVS_tidy_aggregate) # type of the vars
vis_miss(WVS_tidy) # type of the vars
vis_miss(head(WVS_tidy, 10000)) # type of the vars
GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
warnings()
# Selected, filtered and renamed data is saved as GTD_clean:
GTD_clean <- GTD %>%
select(
eventid,
year = iyear,
country = country_txt,
# region = region_txt,
# success, # unsure yet if we should keep only successful attacks or not.
# attacktype1_txt,
# gname, # GTD %$% gname %>% unique() %>% length() ==> 1364 different organisation. Could invest time classify them (e.g. far-left, far-right, islamist)
# nkill # we could dichotomize it in the mutate below: with and without victims.
# targtype1_txt,
) %>%
filter(
# no filter on years ==. years: 1970-2017
# NOTE do not filter on year here, but later. Else adding years without events below is not working
# no filter on country. it will depend on what we have in the other datasets that we join to GTD.
) %>%
mutate(
# didkill = as.factor(ifelse(nkill > 0, "yes", "no")), # note: keeps NA's as NA's (that's good)
# didwound = ifelse(nwound > 0, "yes", "no") # note: keeps NA's as NA's (that's good)
# year = as.factor(year),
country = as.factor(country),
# region = as.factor(region)
) %>% # we sort by country and year (aesthetic):
arrange(country, year) %>% # we sum the number of event by country and year:
count(year, country) %>%
group_by(year, country) %>%
summarise(n_events = sum(n, na.rm = TRUE)) %>%
arrange(country, year)
print("cleaning done")
print("TOTHINK: do we need fatalities too?")
# create "structure" data frame with all the year and country combinations:
countries = GTD_clean %>% filter(year > 1999) %>% .$country %>% unique() %>% rep(18)
