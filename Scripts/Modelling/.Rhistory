library(plotly, warn.conflicts = FALSE)
ggplotly(p1)
View(alcohol1)
help dnorm()
dnorm()?
?dnorm()
?dnorm
set.seed(3000)
xseq<-seq(-4,4,.01)
densities<-dnorm(xseq, 0,1)
cumulative<-pnorm(xseq, 0, 1)
randomdeviates<-rnorm(1000,0,1)
dnorm(x, mean(y), sd(y))
dnorm(0)
norm(0)
dnorm(0)*sqrt(2*pi)
dnorm(0,mean=4)
dnorm(0,mean=4,sd=10)
v <- c(0,1,2)
dnorm(v)
x <- seq(-20,20,by=.1)
y <- dnorm(x)
plot(x,y)
y <- dnorm(x,mean=2.5,sd=0.1)
plot(x,y)
# normal density distribution
x <- seq(-2, 3, 0.1)
y <-  dnorm(x)
plot (x,y)
y <- pnorm(x)
plot (x,y)
x <- seq (0,1, 0.1)
y <- qnorm(x)
plot (x,y)
# numbers randomly generated following the normal distribution
y <- rnorm(100)
plot (y)
?dbinom
dbinom(46:54, 100, 0.5)
plot (y)
?dbinom
y <-  dbinom(46:54, 100, 0.5)
plot (y)
y <-  dbinom(46:54, 100, 0.5)
plot (y)
y <-  dbinom(1:10, 100, 0.5)
plot (y)
first_fit <- lm(weight ~ height, data=women)
first_fit <- lm(weight ~ height, data=women)
summary(first_fit)
women$weight
fitted(fit)
residuals(fit)
plot(women$height,women$weight)
abline(fit)
women$weight
fitted(first_fit)
residuals(first_fit)
plot(women$height,women$weight)
abline(first_fit)
fit<-lm(mpg~(hp+wt+hp)^2, data =mtcars)
summary(fit)
fit<-lm(mpg~(hp*wt*hp)^2, data =mtcars)
summary(fit)
library(lme4)
politeness <- read.csv(file.choose())
head(politeness)
View(politeness)
which(is.na(politeness$frequency))
boxplot(frequency ~ attitude*gender, col=c("white","lightgrey"), politeness)
lmer(frequency ~ attitude, data=politeness)
data(Affairs, package="AER")
library(AER)
data(Affairs)
install.packages("AER")
data(Affairs, package="AER")
Affairs$ynaffair[Affairs$affairs == 0] <- 0
Affairs$ynaffair[Affairs$affairs > 0] <- 1
fit<- glm(ynaffair ~ gender + age+yearsmarried + children +religiousness + education + occupation + rating, data=Affairs, family=binomial())
a1 <- rep(1:4, each=2)
a2 <- rep(1:4, each=2)
A <- cbind(a1, a2)
a2 <- rep(1:4, each=2)
A <- cbind(a1, a2)
mean(A[,1])
mean(A[,2])
apply(A, 2, mean)
apply(A, 2, mean)
apply(A, 2, mean, na.rm = TRUE)
A[1,2] <- 1
A
cmeans <- apply(A,2, mean)
A-matrix(cmeans, nrow =4, ncol =2, byrow=2)
A-matrix(cmeans, nrow =4, ncol =2, byrow=TRUE)
A
cmeans <- apply(A,2, mean)
matrix(cmeans, nrow =4, ncol =2, byrow=TRUE)
sweep(A, n, cmeans, FUN= "-")
sweep(A, 2, cmeans, FUN= "-")
source('~/Desktop/NotesMath.R', echo=TRUE)
B <- matrix(1:4, ncol=2, nrow=2)
A %% diag(rep(2,2))
diag(rep(2,2))
A %*% diag(rep(2,2))
theta <- 60
theta2 <- (2*pi*theta)/360
theta
theta2
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
sweep(A, n, cmeans, FUN= "-")
theta
theta2
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix (c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE)
X <- matrix(c(0.7, 1.2, 0.25 0.8), ncol=2)
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
plot(0,0)
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0,1,1)
arrows(0,0,1,1,lwd=3,lenght=0.1)
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0, X[1,], X[2,], lwd=3)
Y <- R %*%X
arrows(0,0, Y[1,], X[2,], lwd=3, col="grey")
arrows(0,0, Y[1,], Y[2,], lwd=3, col="grey")
Y <- R %*%X
Y <- R%*%X
Y <- R %*% X
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
arrows(0,0,1,1,lwd=3,lenght=0.1)
arrows(0,0, X[1,], X[2,], lwd=3)
arrows(0,0,1,1,lwd=3,length=0.1)
arrows(0,0, X[1,], X[2,], lwd=3)
X
Y <- R %*% X
arrows(0,0, Y[1,], Y[2,], lwd=3, col="grey")
plot(0,0, type="n", xlim=c(-1.5,1.5), ylim=c(0,1.5))
arrows(0,0, X[1,], X[2,], lwd=3)
Y <- R %*% X
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), ncol=2)
Y <- R %*% X
X <- matrix(c(0.7, 1.2, 0.25, 0.8), nrow=2, ncol=2)
Y <- R %*% X
u <- c(2,1)
u %*% t8u)
u %*% t(u)
t(u) %*% u
R <- matrix(c(cos(theta2), -sin(theta2), sin(theta2), cos(theta2), nrow=2, ncol=2, byrow=TRUE))
X <- matrix(c(0.7, 1.2, 0.25, 0.8), nrow=2, ncol=2, byrow=TRUE)
Y <- R %*% X
as.numeric(t(u) %*% u)
Pu <- u %*% t(u)
Pu
Pu <- u %*% t(u)
Pu
Pu <- u %*% t(u) / as.numeric(t(u) %*% u)
Pu
x <- c(2,2)
Pu %*% x
plot(0,0, type="n", xlim=c(0,4), ylim=c(0,3))
abline(0, 0.5, lwd=2, col="blue")
points(2.4,1.2, pch=14)
points(2.4,1.2, pch=16)
points(2,2)
locator(1)
points(x1[1], x1[2], col="red")
points(x1[1], x1[2], col="red")
x1 <- c(0.26,1.73)
points(x1[1], x1[2], col="red")
points(z1[1], z1[2], col="red")
z1 <- c(0.9,0.45)
points(z1[1], z1[2], col="red")
A <-  matrix(c(7,4,3,4,6,4,3,4,7), ncol=3)
A
Ae <- eigen(A)
Ae
Ae$values
Ae[[1]]
D <- diag(Ae$values)
D
V <- Ae$vectors
V %*% D %*% t(V)
A
B <-  matrix(c(-1, -1, 0, 1, 1, 1:10, (1:5)^2, ncol=4))
B
B <-  matrix(c(-1, -1, 0, 1, 1, 1:10, (1:5)^2), ncol=4)
B
Bs <-  svd(B)
Bs
Bs$u %*% diag(Bs$d) %*% t(Bs$v)
x <- seq(20, 50, 1)
y <-  (7000 - 400*x + 10*x^2)/3
plot(x,y,type="l")
y[2]-y[1]
diff(y)
plot (x[-1]], diff(y), type="l")
plot (x[-1], diff(y), type="l")
y <-(7000 - 400*x + 10*x^2)/3
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
# add theoretical derivative
abline(-400/3, 20/3, col=2)
delta <- 1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y), type="l")
abline(-400/3, 20/3, col=2)
delta <- 0.1
x <-  seq(20, 50, delta)
y <-(7000 - 400*x + 10*x^2)/3
plot (x[-1], diff(y)/delta, type="l")
abline(-400/3, 20/3, col=2)
f <-  function(x1,x2) {return(x1^3 - x2^2)}
x1 <- x2 <- seq(-2, 2 , length = 25)
Y <-  outer(x1, x2, f)
persp(x1, x2, Y)
abline(h=0)
abline(v=0)
pmat <- persp(x1, x2, Y, theta = -30)
pmat
p1 <- -0.5
p2 <- -3/4
p3 <- f(p1,p2)
p3
trans3d(p1,p2,p3,pmat)
points(trans3d(p1,p2,p3,pmat), col =2, pch= 16)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
plot(x, y, type ="l")
integrate(dnorm, 0, 1)
x <- seq(-4, 4, length = 500)
y <- dnorm(x)
integrate(dnorm, 0, 1)
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1))
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0,01), 1, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgray")
polygon(x0, y0, col = "lightgrey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
polygon(x0, y0, col = "lightgrey")
y0 <- c(0, dnorm(seq(0,1,0.1)), 0, 0)
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(c(-1, 1, 1, -1, -1), c(0.1, 0.1, 0.2, 0.2, 0.1), col="grey")
x0 <- c(0, seq(0,1,0.01), 1, 0)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
polygon(x0, y0, col = "lightgrey")
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(0,1,0.01)), 0, 0)
x0 <- c(-2, seq(0,1,0.01), 2, -2)
y0 <- c(0, dnorm(seq(-2,2,0.01)), 0, 0)
polygon(x0, y0, col = "blue")
polygon(x0, y0, col = "blue")
integrate(dnorm, -2, 2)
pnorm(2) - pnorm(-2)
pnorm(2, 2, 1) - pnorm(-2, 2, 1)
install.packages("RSiena", repos="http://R-Forge.R-project.org")
install.packages("RSiena")
install.packages("RSiena", repos="http://R-Forge.R-project.org", (options(download.file.method = NULL)))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org", options(download.file.method = NULL))
# if you don't have the RSiena package installed
# install it - from R-Forge! (the version at CRAN is older)
install.packages("RSiena", repos="http://R-Forge.R-project.org"), (options(download.file.method = NULL)))
?install.packages
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]])
install.packages("RSiena", repos = getOption("repos")[["http://R-Forge.R-project.org"]]))
install.packages("RSiena", repos = getOption("http://R-Forge.R-project.org"))
install.packages("RSiena", options(download.file.method = NULL))
install.packages("RSiena")
# loading necessary packages
library(RSiena)
sienaAlgorithmCreate
install.packages("tm")
install.packages("reshape2")
install.packages("tidyverse")
library(tidyverse)
library(rio)
rio::import("/Users/schwarze/Documents/HARVARD/TechTogether")
rio::import(".../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2")
rio::import("../Users/schwarze/Documents/HARVARD/TechTogether/FY2019_4050_FMRs_rev2.xlsx")
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(politeness)
View(fit)
View(first_fit)
rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
fairrent <- rio::import("../TechTogether/FY2019_4050_FMRs_rev2.xlsx")
View(fairrent)
library(tidyverse)
library(pglm) # model panel data
library(pscl)
library(lme4) # models longitudinal data within a Generalized Linear Mixed Model (GLMM) framework,
# Note that glmer implements random, rather than fixed effects.
# If you're attempting inference and want to control for all cross-sectional heterogeneity, glmer won't get you there. You'd need some implementation of the conditional logit model
library(robustHD) # data standardization
library(Hmisc)
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(lmtest) # for coefplot
library(sjPlot)
library(sjmisc)
library(sjlabelled)
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Modelling")
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
table(my_data$n_events)
summary(my_data$n_events)
summary(my_data$n_domtarg_events)
describe(my_data$n_events)
describe(n_domtarg_events)
describe(my_data$n_domtarg_events)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Modelling")
library(tidyverse)
library(pglm) # model panel data
library(pscl)
library(lme4) # models longitudinal data within a Generalized Linear Mixed Model (GLMM) framework,
# Note that glmer implements random, rather than fixed effects.
# If you're attempting inference and want to control for all cross-sectional heterogeneity, glmer won't get you there. You'd need some implementation of the conditional logit model
library(robustHD) # data standardization
library(Hmisc)
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(lmtest) # for coefplot
library(sjPlot)
library(sjmisc)
library(sjlabelled)
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
View(my_data)
# ----------------  summary statistics :
stargazer(my_data, type="text") # To create a summary statistics table (select variables?)
stargazer(my_data, type="html", out="descriptives.htm") # To create a summary statistics table (select variables?)
getw()
getwd()
table(my_data$n_domtarg_events)
describe(my_data$n_domtarg_events)
describe(my_data$n_events)
frequency(my_data$n_events)
sum(is.na(my_data$n_events))
sum(is.na(my_data$n_domtarg_events))
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Data Processing/Functions to Tidy Data")
GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
describe(GTD$n_events)
# Aim of this function:
#   read the GTD data, select the variables of interest, add new computed variables if needed, and,
#   save the output as GTD_tidy.rds.
# Note: this function is called from tidy_datasets.R
tidy_GTD <- function(path_loadoriginal, path_savetidy){
#       1. read GTD
print("importing GTD data... (30sec.)")
GTD <- rio::import(path_loadoriginal)
# GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
print("importing done")
#       2. data selection
# quick ways to have a look at the data:
# GTD %$% iyear %>% unique() # look at all unique values of a column
# glimpse(GTD) # list all columns, what type of element they contain and the first values as examples
# table(GTD$attacktype1_txt) # table of occurrences. only for non-continuous data (typically factors)
# table(GTD_tidy$nkill, useNA = "ifany") # use this option to show if they are NAs in the column.
# Selected, filtered and renamed data is saved as GTD_clean:
GTD_clean <- GTD %>%
select(
eventid,
year = iyear,
country = country_txt,
nationality_location = INT_LOG, # nationality of perpetrator == location of attack
# nationality_nationality = INT_IDEO, # nationality of perpetrator == nationality of target
location_nationality = INT_MISC # location of attack == nationality of target
# region = region_txt,
# success, # unsure yet if we should keep only successful attacks or not.
# attacktype1_txt,
# gname, # GTD %$% gname %>% unique() %>% length() ==> 1364 different organisation. Could invest time classify them (e.g. far-left, far-right, islamist)
# nkill # we could dichotomize it in the mutate below: with and without victims.
# targtype1_txt,
) %>%
filter(
# no filter on years ==. years: 1970-2017
# NOTE do not filter on year here, but later. Else adding years without events below is not working
# no filter on country. it will depend on what we have in the other datasets that we join to GTD.
) %>%
mutate(
# didkill = as.factor(ifelse(nkill > 0, "yes", "no")), # note: keeps NA's as NA's (that's good)
# didwound = ifelse(nwound > 0, "yes", "no") # note: keeps NA's as NA's (that's good)
# year = as.factor(year),
country = as.factor(country)
# region = as.factor(region)
) %>% # we sort by country and year (aesthetic):
arrange(country, year)
GTD_clean_events <- GTD_clean %>% # we sum the number of event by country and year:
count(year, country, name = "n_events") %>%
# group_by(year, country) %>%
# summarise(n_events = sum(n, na.rm = TRUE)) %>%
arrange(country, year)
GTD_clean_domesticperpetrator <- GTD_clean %>%
filter(nationality_location == 0) %>%
count(year, country, name = "n_domperp_events") %>%
arrange(country, year)
GTD_clean_domestictarget <- GTD_clean %>%
filter(location_nationality == 0) %>%
count(year, country, name = "n_domtarg_events") %>%
arrange(country, year)
# merge all 3 in one dataset:
GTD_clean <- left_join(GTD_clean_events, GTD_clean_domesticperpetrator)
GTD_clean <- left_join(GTD_clean, GTD_clean_domestictarget)
# Aim of this function:
#   read the GTD data, select the variables of interest, add new computed variables if needed, and,
#   save the output as GTD_tidy.rds.
# Note: this function is called from tidy_datasets.R
tidy_GTD <- function(path_loadoriginal, path_savetidy){
#       1. read GTD
print("importing GTD data... (30sec.)")
GTD <- rio::import(path_loadoriginal)
# GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
print("importing done")
#       2. data selection
# quick ways to have a look at the data:
# GTD %$% iyear %>% unique() # look at all unique values of a column
# glimpse(GTD) # list all columns, what type of element they contain and the first values as examples
# table(GTD$attacktype1_txt) # table of occurrences. only for non-continuous data (typically factors)
# table(GTD_tidy$nkill, useNA = "ifany") # use this option to show if they are NAs in the column.
# Selected, filtered and renamed data is saved as GTD_clean:
GTD_clean <- GTD %>%
select(
eventid,
year = iyear,
country = country_txt,
nationality_location = INT_LOG, # nationality of perpetrator == location of attack
# nationality_nationality = INT_IDEO, # nationality of perpetrator == nationality of target
location_nationality = INT_MISC # location of attack == nationality of target
# region = region_txt,
# success, # unsure yet if we should keep only successful attacks or not.
# attacktype1_txt,
# gname, # GTD %$% gname %>% unique() %>% length() ==> 1364 different organisation. Could invest time classify them (e.g. far-left, far-right, islamist)
# nkill # we could dichotomize it in the mutate below: with and without victims.
# targtype1_txt,
) %>%
filter(
# no filter on years ==. years: 1970-2017
# NOTE do not filter on year here, but later. Else adding years without events below is not working
# no filter on country. it will depend on what we have in the other datasets that we join to GTD.
) %>%
mutate(
# didkill = as.factor(ifelse(nkill > 0, "yes", "no")), # note: keeps NA's as NA's (that's good)
# didwound = ifelse(nwound > 0, "yes", "no") # note: keeps NA's as NA's (that's good)
# year = as.factor(year),
country = as.factor(country)
# region = as.factor(region)
) %>% # we sort by country and year (aesthetic):
arrange(country, year)
GTD_clean_events <- GTD_clean %>% # we sum the number of event by country and year:
count(year, country, name = "n_events") %>%
# group_by(year, country) %>%
# summarise(n_events = sum(n, na.rm = TRUE)) %>%
arrange(country, year)
GTD_clean_domesticperpetrator <- GTD_clean %>%
filter(nationality_location == 0) %>%
count(year, country, name = "n_domperp_events") %>%
arrange(country, year)
GTD_clean_domestictarget <- GTD_clean %>%
filter(location_nationality == 0) %>%
count(year, country, name = "n_domtarg_events") %>%
arrange(country, year)
# merge all 3 in one dataset:
GTD_clean <- left_join(GTD_clean_events, GTD_clean_domesticperpetrator)
GTD_clean <- left_join(GTD_clean, GTD_clean_domestictarget)
print("cleaning done")
GTD <- rio::import("../../../Data/Original Data/GTD/globalterrorismdb_0718dist.xlsx")
describe(GTD$eventid)
describe(GTD$INT_LOG)
describe(GTD$INT_MISC)
setwd("~/Documents/GitHub/LegitimacyTerrorism/Scripts/Modelling")
library(tidyverse)
library(pglm) # model panel data
library(pscl)
library(lme4) # models longitudinal data within a Generalized Linear Mixed Model (GLMM) framework,
# Note that glmer implements random, rather than fixed effects.
# If you're attempting inference and want to control for all cross-sectional heterogeneity, glmer won't get you there. You'd need some implementation of the conditional logit model
library(robustHD) # data standardization
library(Hmisc)
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(lmtest) # for coefplot
library(sjPlot)
library(sjmisc)
library(sjlabelled)
my_data <- readRDS("../../Data/Data for Modelling/GTD_polity_PENN_PRIO_WGI_2000.rds")
glimpse(my_data)
#
# ----------------  correlation matrix :
corrleg <- cor(my_data %>% select(accountability,corruption,effectiveness,quality,rule_of_law, polity2), use = "pairwise.complete.obs")
stargazer(corrleg,type="html", out="correlation_matrix.htm")
getwd()
